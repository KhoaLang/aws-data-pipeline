import sys

from pyspark.sql.functions import *
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Spark job on EMR").getOrCreate()

new_df = (
    spark.read.option("inferSchema", "true").option("header", "true").csv(sys.argv[1])
)  # sys.argv[1] is the full S3 uri for input dataset

new_df2 = new_df.select("time_received", "download_source", "top_level_domain")

new_df2.write.format("parquet").mode("overwrite").save(
    sys.argv[2]
)  # this is also full S3 uri for output destination file
